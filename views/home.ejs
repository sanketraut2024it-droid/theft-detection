<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Live Monitor - Theft Detection</title>
  <link rel="stylesheet" href="/style.css">
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      min-height: 100vh;
      color: #333;
    }
    .navbar {
      background: rgba(255, 255, 255, 0.95);
      padding: 1rem 2rem;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      display: flex;
      justify-content: space-between;
      align-items: center;
      flex-wrap: wrap;
    }
    .navbar h1 {
      color: #667eea;
      font-size: 1.5rem;
    }
    .nav-links {
      display: flex;
      gap: 1rem;
      flex-wrap: wrap;
    }
    .nav-links a {
      text-decoration: none;
      padding: 0.5rem 1rem;
      border-radius: 5px;
      color: #333;
      transition: all 0.3s;
    }
    .nav-links a:hover {
      background: #667eea;
      color: white;
    }
    .container {
      max-width: 1200px;
      margin: 2rem auto;
      padding: 0 2rem;
      text-align: center;
    }
    .monitor-card {
      background: white;
      padding: 2rem;
      border-radius: 12px;
      box-shadow: 0 4px 6px rgba(0,0,0,0.1);
      margin-bottom: 2rem;
    }
    .monitor-card h2 {
      color: #667eea;
      margin-bottom: 1.5rem;
    }
    video {
      width: 100%;
      max-width: 640px;
      height: auto;
      border: 4px solid #667eea;
      border-radius: 12px;
      margin: 1rem 0;
      background: #000;
    }
    .status {
      padding: 1rem;
      background: #f3f4f6;
      border-radius: 8px;
      margin: 1rem 0;
      font-size: 1.1rem;
      color: #667eea;
      font-weight: bold;
    }
    .status.active {
      background: #d1fae5;
      color: #059669;
    }
    .status.alert {
      background: #fee2e2;
      color: #dc2626;
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.7; }
    }
    .stats {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 1rem;
      margin-top: 2rem;
    }
    .stat-item {
      background: #f3f4f6;
      padding: 1rem;
      border-radius: 8px;
    }
    .stat-item h3 {
      color: #667eea;
      font-size: 0.9rem;
      margin-bottom: 0.5rem;
    }
    .stat-item .value {
      font-size: 1.5rem;
      font-weight: bold;
      color: #333;
    }
    .btn {
      display: inline-block;
      padding: 0.75rem 1.5rem;
      background: #667eea;
      color: white;
      text-decoration: none;
      border-radius: 8px;
      border: none;
      cursor: pointer;
      font-size: 1rem;
      transition: all 0.3s;
      margin: 0.5rem;
    }
    .btn:hover {
      background: #5568d3;
      transform: translateY(-2px);
    }
    .btn-danger {
      background: #ef4444;
    }
  </style>
</head>
<body>
  <nav class="navbar">
    <h1>üî¥ Live Monitoring</h1>
    <div class="nav-links">
      <a href="/dashboard">Dashboard</a>
      <a href="/home">Live Monitor</a>
      <a href="/gallery">Gallery</a>
      <a href="/alerts">Alerts</a>
      <a href="/settings">Settings</a>
      <a href="/faces">Faces</a>
      <form action="/logout" method="POST" style="display: inline;">
        <button type="submit" class="btn btn-danger" style="padding: 0.5rem 1rem;">Logout</button>
      </form>
    </div>
  </nav>

  <div class="container">
    <div class="monitor-card">
      <h2>üë§ Welcome, <%= user ? user.name : "User" %></h2>
      
      <div style="position: relative; display: inline-block;">
        <video id="cam" autoplay playsinline></video>
        <canvas id="faceCanvas" style="position: absolute; top: 0; left: 0; pointer-events: none;"></canvas>
      </div>
      
      <div id="faceInfo" style="margin: 1rem 0; padding: 1rem; background: #f3f4f6; border-radius: 8px; display: none;">
        <h3 style="color: #667eea; margin-bottom: 0.5rem;">üë§ Face Recognition Info</h3>
        <div id="faceDetails" style="color: #333;"></div>
      </div>
      
      <!-- Captured Image Display Area -->
      <div id="capturedImageDisplay" style="display: none; margin: 1rem 0; padding: 1rem; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
        <!-- Will be populated by script.js when images are captured -->
      </div>
      
      <div id="status" class="status active">üîç Monitoring...</div>
      
      <div id="stats" class="stats">
        <div class="stat-item">
          <h3>Status</h3>
          <div class="value" id="statusValue">Active</div>
        </div>
        <div class="stat-item">
          <h3>Detections Today</h3>
          <div class="value" id="todayCount">0</div>
        </div>
        <div class="stat-item">
          <h3>Total Captures</h3>
          <div class="value" id="totalCount">0</div>
        </div>
      </div>
    </div>
  </div>

  <audio id="alertSound" src="/sound/alert.mp3"></audio>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script src="/script.js"></script>

  <script>
    let soundEnabled = <%= user.settings.soundAlerts ? 'true' : 'false' %>;
    let lastCheckTime = null;
    let detectionCount = 0;

    // Load statistics on page load
    async function loadStats() {
      try {
        const response = await fetch('/api/stats');
        const data = await response.json();
        if (data.success) {
          document.getElementById('todayCount').textContent = data.stats.capturesToday;
          document.getElementById('totalCount').textContent = data.stats.totalCaptures;
        }
      } catch (error) {
        console.error('Error loading stats:', error);
      }
    }

    // Check for new captures
    async function checkForNewCaptures() {
      try {
        const response = await fetch('/api/check-new');
        const data = await response.json();

        if (data.newCapture && data.capture) {
          if (data.capture.faceRecognized && data.capture.recognizedFaceName) {
            console.log(`‚ÑπÔ∏è Known person detected (${data.capture.recognizedFaceName}) - no live alert shown`);
            return;
          }

          detectionCount++;
          const statusEl = document.getElementById('status');
          const statusValue = document.getElementById('statusValue');
          
          // Determine alert message based on face recognition
          let alertMessage = 'üö® Motion Detected!';
          let alertBody = 'Your theft detection system has detected movement.';
          let isAlert = false; // Whether this should trigger an alert
          
          if (data.capture.faceDetected) {
            if (data.capture.faceRecognized && data.capture.recognizedFaceName) {
              // Known person - no alert
              alertMessage = `‚úÖ ${data.capture.recognizedFaceName} Detected`;
              alertBody = `Known person detected: ${data.capture.recognizedFaceName}`;
              statusEl.className = 'status active'; // Green for known person
              isAlert = false;
            } else {
              // Unknown person - ALERT!
              alertMessage = 'üö® Unknown Person Detected!';
              alertBody = 'An unknown person has been detected! Alert sent.';
              statusEl.className = 'status alert'; // Red for unknown
              isAlert = true;
            }
          } else {
            // Motion without face - ALERT!
            alertMessage = 'üö® Motion Detected!';
            alertBody = 'Motion detected but no face identified. Alert sent.';
            statusEl.className = 'status alert'; // Red for motion
            isAlert = true;
          }
          
          statusEl.textContent = alertMessage;
          statusValue.textContent = isAlert ? 'Alert!' : 'Detected';
          document.getElementById('todayCount').textContent = parseInt(document.getElementById('todayCount').textContent) + 1;

          // Play sound and show notification ONLY for alerts (unknown faces or motion)
          if (isAlert) {
            // Play sound if enabled
            if (soundEnabled) {
              const sound = document.getElementById('alertSound');
              sound.play().catch(err => {
                console.log('Sound play failed:', err);
              });
            }

            // Show browser notification
            if (Notification.permission === 'granted') {
              new Notification(alertMessage, {
                body: alertBody,
                icon: '/sound/alert.mp3'
              });
            }
            
            console.log('üö® ALERT TRIGGERED:', alertMessage);
          } else {
            console.log('‚ÑπÔ∏è Known person detected - no alert');
          }

          // Reset status after 5 seconds
          setTimeout(() => {
            statusEl.className = 'status active';
            statusEl.textContent = 'üîç Monitoring...';
            statusValue.textContent = 'Active';
          }, 5000);
        }
      } catch (error) {
        console.error('Error checking for new captures:', error);
      }
    }

    // Request notification permission
    if ('Notification' in window && Notification.permission === 'default') {
      Notification.requestPermission();
    }

    // Real-time face recognition display
    let faceCanvas = null;
    let faceCtx = null;
    let knownFaces = [];
    
    // Initialize face recognition canvas
    function initFaceCanvas() {
      faceCanvas = document.getElementById('faceCanvas');
      const video = document.getElementById('cam');
      
      if (faceCanvas && video) {
        faceCanvas.width = video.videoWidth || 640;
        faceCanvas.height = video.videoHeight || 480;
        faceCtx = faceCanvas.getContext('2d');
      }
    }
    
    // Load known faces for recognition
    async function loadKnownFaces() {
      try {
        const response = await fetch('/api/faces');
        const data = await response.json();
        if (data.success) {
          knownFaces = data.faces || [];
          console.log(`Loaded ${knownFaces.length} known faces for recognition`);
        }
      } catch (error) {
        console.error('Error loading known faces:', error);
      }
    }
    
    // Recognize face by comparing with known faces
    async function recognizeFace(descriptor) {
      if (!descriptor || knownFaces.length === 0) {
        return null;
      }
      
      try {
        // Normalize descriptor
        const magnitude = Math.sqrt(descriptor.reduce((sum, val) => sum + val * val, 0));
        if (magnitude === 0) return null;
        const normalized = descriptor.map(val => val / magnitude);
        
        let bestMatch = null;
        let minDistance = Infinity;
        const threshold = 0.6;
        
        for (const knownFace of knownFaces) {
          if (!knownFace.descriptor) continue;
          
          // Calculate Euclidean distance
          let sum = 0;
          for (let i = 0; i < normalized.length && i < knownFace.descriptor.length; i++) {
            const diff = normalized[i] - knownFace.descriptor[i];
            sum += diff * diff;
          }
          const distance = Math.sqrt(sum);
          
          if (distance < minDistance) {
            minDistance = distance;
            bestMatch = knownFace;
          }
        }
        
        if (minDistance < threshold && bestMatch) {
          const confidence = Math.round((1 - minDistance / threshold) * 100);
          return {
            name: bestMatch.name,
            confidence: confidence,
            distance: minDistance
          };
        }
      } catch (error) {
        console.error('Face recognition error:', error);
      }
      
      return null;
    }
    
    // Draw face detection and recognition on canvas
    async function drawFaceRecognition() {
      const modelsLoaded = window.faceDetectionModelsLoaded ? window.faceDetectionModelsLoaded() : false;
      const detectionEnabled = window.faceDetectionEnabled ? window.faceDetectionEnabled() : false;
      
      if (!faceCtx || !detectionEnabled || !modelsLoaded) {
        return;
      }
      
      const video = document.getElementById('cam');
      if (!video || video.videoWidth === 0) {
        return;
      }
      
      // Update canvas size to match video
      if (faceCanvas.width !== video.videoWidth || faceCanvas.height !== video.videoHeight) {
        faceCanvas.width = video.videoWidth;
        faceCanvas.height = video.videoHeight;
      }
      
      // Clear canvas
      faceCtx.clearRect(0, 0, faceCanvas.width, faceCanvas.height);
      
      try {
        // Detect faces
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
          .withFaceLandmarks()
          .withFaceDescriptors()
          .withAgeAndGender();
        
        if (detections.length > 0) {
          document.getElementById('faceInfo').style.display = 'block';
          
          for (const detection of detections) {
            const box = detection.detection.box;
            const descriptor = Array.from(detection.descriptor);
            
            // Try to recognize the face
            const recognition = await recognizeFace(descriptor);
            
            // Draw detection box
            faceCtx.strokeStyle = recognition ? '#00ff00' : '#ff0000';
            faceCtx.lineWidth = 2;
            faceCtx.strokeRect(box.x, box.y, box.width, box.height);
            
            // Draw landmarks
            if (detection.landmarks) {
              faceCtx.fillStyle = recognition ? '#00ff00' : '#ff0000';
              detection.landmarks.positions.forEach(point => {
                faceCtx.beginPath();
                faceCtx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                faceCtx.fill();
              });
            }
            
            // Display recognition info
            let infoText = '';
            if (recognition) {
              infoText = `‚úÖ ${recognition.name} (${recognition.confidence}%)`;
            } else {
              infoText = '‚ùå Unknown Person';
            }
            
            if (detection.age && detection.gender) {
              infoText += ` | ${detection.gender}, ~${Math.round(detection.age)} years`;
            }
            
            // Draw text background
            faceCtx.fillStyle = recognition ? 'rgba(0, 255, 0, 0.7)' : 'rgba(255, 0, 0, 0.7)';
            faceCtx.fillRect(box.x, box.y - 30, box.width, 25);
            
            // Draw text
            faceCtx.fillStyle = '#ffffff';
            faceCtx.font = '14px Arial';
            faceCtx.fillText(infoText, box.x + 5, box.y - 10);
            
            // Update face info display
            let detailsHtml = `<strong>Status:</strong> ${recognition ? 'Recognized' : 'Unknown'}<br>`;
            if (recognition) {
              detailsHtml += `<strong>Name:</strong> ${recognition.name}<br>`;
              detailsHtml += `<strong>Confidence:</strong> ${recognition.confidence}%<br>`;
            }
            if (detection.age && detection.gender) {
              detailsHtml += `<strong>Gender:</strong> ${detection.gender}<br>`;
              detailsHtml += `<strong>Age:</strong> ~${Math.round(detection.age)} years<br>`;
            }
            detailsHtml += `<strong>Detection Confidence:</strong> ${Math.round(detection.detection.score * 100)}%`;
            
            document.getElementById('faceDetails').innerHTML = detailsHtml;
          }
        } else {
          document.getElementById('faceInfo').style.display = 'none';
        }
      } catch (error) {
        console.error('Face recognition display error:', error);
      }
    }
    
    // Initialize face recognition when models are loaded
    let recognitionInterval = null;
    function startFaceRecognition() {
      if (recognitionInterval) {
        clearInterval(recognitionInterval);
      }
      
      // Wait for models to load
      const checkModels = setInterval(() => {
        const modelsLoaded = typeof faceapi !== 'undefined' && 
          (window.faceDetectionModelsLoaded ? window.faceDetectionModelsLoaded() : false);
        
        if (modelsLoaded) {
          clearInterval(checkModels);
          initFaceCanvas();
          loadKnownFaces();
          
          // Draw face recognition every 500ms
          recognitionInterval = setInterval(drawFaceRecognition, 500);
        }
      }, 500);
    }
    
    // Start checking for new captures every 2 seconds (more frequent for better responsiveness)
    setInterval(checkForNewCaptures, 2000);
    
    // Also check immediately on page load
    checkForNewCaptures();
    
    // Load stats on page load
    loadStats();
    setInterval(loadStats, 30000); // Refresh stats every 30 seconds
    
    // Debug: Log when checking for new captures
    console.log('‚úÖ Alert monitoring started - checking every 2 seconds');
    
    // Start face recognition
    startFaceRecognition();
    
    // Reload known faces periodically
    setInterval(loadKnownFaces, 60000); // Every minute
  </script>
</body>
</html>
